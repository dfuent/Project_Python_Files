{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Presidential and Vice Presidential Debate scraper\n",
    "\n",
    "## Polisticians Semester Project\n",
    "### data sourced from CPD website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements for packages to be used later\n",
    "\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from urllib.request import Request, urlopen\n",
    "import pandas as pd\n",
    "import time\n",
    "import io\n",
    "from selenium import webdriver\n",
    "from ftfy import fix_encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the webscraper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcript_scraper():\n",
    "    \n",
    "    # Option so that selenium doesn't open a new Chrome window with each pull\n",
    "    \n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    \n",
    "    t_0 = time.time() # will use to time the process later\n",
    "     \n",
    "    # input headers in a dict to bypass issue loading transcript site\n",
    "    \n",
    "    hd = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "           'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "           'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "           'Accept-Encoding': 'none',\n",
    "           'Accept-Language': 'en-US,en;q=0.8',\n",
    "           'Connection': 'keep-alive'}\n",
    "    \n",
    "    # URL base, from which we pull the set of links \n",
    "    \n",
    "    root = 'https://www.debates.org/voter-education/debate-transcripts'\n",
    "    \n",
    "    # send request to site with headers to bypass Forbidden issue\n",
    "    req = Request(root, headers = hd)\n",
    "    \n",
    "    # read site\n",
    "    \n",
    "    html_page = urlopen(req).read()\n",
    "    \n",
    "    # create HTML \"soup\" from which we will pull our information\n",
    "    \n",
    "    soup = BeautifulSoup(html_page, \"lxml\")\n",
    "    \n",
    "    # initiate web driver for Chrome\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    #use driver to open root url specified earlier\n",
    "    driver.get(root)\n",
    "    \n",
    "    links = [] # empty list to which we will append the links to the transcripts\n",
    "    \n",
    "    for link in soup.findAll('a'): # locate the link\n",
    "        links.append(str(link.get('href'))) # append the link to the link list\n",
    "    \n",
    "    # we only want the data if the link contains 'transcript', which is the convention used by the CPD\n",
    "    t = [i for i in links if 'transcript' in i] \n",
    "    \n",
    "    t = list(set(t)) # use set to ensure that there won't be anyu \n",
    "    \n",
    "    fin_list = [] # empty list to which we will input the transcript strings\n",
    "    \n",
    "    for i in t: # iterate through our list of links\n",
    "        \n",
    "        loop_time = time.time()\n",
    "\n",
    "        url = 'https://www.debates.org/' + str(i) # create the transcript URL\n",
    "        \n",
    "        #print(url) # for testing\n",
    "        \n",
    "        #Option so that selenium doesn't open a new Chrome window during each loop\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--headless')\n",
    "        \n",
    "        #initiate web driver\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        \n",
    "        #use driver to open url\n",
    "        driver.get(url)\n",
    "        \n",
    "        #wait three seconds to load page, just in casse\n",
    "        time.sleep(3)\n",
    "        \n",
    "        #extract page HTML and parse with BeautifulSoup\n",
    "        html=driver.page_source\n",
    "        soup=BeautifulSoup(html,'html.parser')\n",
    "        \n",
    "        # open file for appending ('a') # test appending data to text\n",
    "        #f = io.open('debate_final.txt', 'a', encoding = 'utf-8')\n",
    "        \n",
    "        # transcript name and date are tagged with 'h1' on the website, so we pull those data\n",
    "        h = soup('h1')\n",
    "        h = str(h)[1:-1].replace('<h1>', '').replace('</h1>', '') # replace the taggings so the data are clean\n",
    "        #print(h) # print the transcript for testing\n",
    "          \n",
    "        tr = str(soup('p')) # pull each block of the transcript parsed above\n",
    "        spl_tr = tr.split('</p>') # split the transcript into each speaker's block of text\n",
    "        \n",
    "        \n",
    "        ## Speaker identification and transcript cleansing steps ##\n",
    "        \n",
    "        \n",
    "        l = 1 # will use this as a counter to indicate the transcript line \n",
    "        speaker = ''\n",
    "        for j in spl_tr:\n",
    "            fix_encoding(j)\n",
    "            j = j.replace('<p>', '')\n",
    "            j = j.replace('</p>', '') # similarly remove HTML tagging from each block of transcript text\n",
    "            j = j[2:].strip() # set the transcript block\n",
    "            \n",
    "            # find first instance of a space in the block of text. If word is Mr., Ms., or Mrs., remove it \n",
    "            \n",
    "            if j.split(' ', 1)[0].strip() in['MR.', 'MS.', 'MRS.' ]: \n",
    "                temp = j.split(' ', 1)[1].strip()\n",
    "                first_word = temp.split(' ', 1)[0]\n",
    "                #print(type(first_word), first_word)\n",
    "            else:\n",
    "                \n",
    "                # otherwise, take the first word from the block, which will be the speaker name in most instances\n",
    "                \n",
    "                first_word = j.split(' ', 1)[0].strip() \n",
    "            \n",
    "            # the majority of transcripts follow the convention <Speaker>: <Transcript>. \n",
    "            # We want to check each block of text's first word for a colon to see if we have a speaker\n",
    "            \n",
    "            try: \n",
    "                    \n",
    "                last_char = first_word[-1] # pull the last character in the first string\n",
    "                \n",
    "            except:\n",
    "                last_char = '' # if there is an error due to empty data, set the string to a blank\n",
    "\n",
    "            #print(last_char)\n",
    "            try:\n",
    "            \n",
    "            # our initial stab at setting a speaker for each block of text sets the speaker as the word before the colon\n",
    "                if last_char == ':' and first_word.upper() == first_word:\n",
    "                    #print(True)\n",
    "                    speaker = first_word.replace(':', '') # replace the colon\n",
    "                    #print(speaker)\n",
    "            except:\n",
    "                \n",
    "                # if there's an error, the data aren't in the <Speaker>: <Transcript> format in which we are interested, \n",
    "                # so we skip to next the next transcript\n",
    "                # BUT, in this case, if there's no speaker in the text, we want to keep the prior speaker since this \n",
    "                # block of text is likely associated with the same speaker. We tested this later on\n",
    "                \n",
    "                continue \n",
    "                    \n",
    "            fin_list.append((l, h, speaker, j)) # append the line count, debate title, speaker, and \n",
    "            #f.write(str(l) +',' + h + ',' + speaker + ',' +  j)\n",
    "            \n",
    "            l += 1 # add one to the line count\n",
    "        \n",
    "        # How many loops have run and in how long?\n",
    "        \n",
    "        print('{0} loops for {1} took {2: .2f} seconds.'.format(l, h, time.time()-loop_time))\n",
    "\n",
    "     \n",
    "        ######################################     \n",
    "    \n",
    "    # once we've looped through each debate link, collecting each block of text, corresponding speaker,\n",
    "    # line count and the debate title and date, we need to create a data from from this list\n",
    "    \n",
    "    \n",
    "    # set columns from list created in loop and insert data\n",
    "    df = pd.DataFrame(fin_list, columns = ['Line Count', 'Debate', 'Speaker', 'Transcript']) \n",
    "    df.to_csv('Transcripts_df.csv', index = False) # save dataframe to csv (no index)\n",
    "        \n",
    "    print('Finished in {0: .2f} seconds'.format(time.time()-t_0)) # let the user know the process worked\n",
    "    \n",
    "    #return fin_list # have the function return the list, if you'd like\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the function!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174 loops for October 3, 2000 Transcript took  6.57 seconds.\n",
      "114 loops for October 5, 2000 Debate Transcript took  6.58 seconds.\n",
      "20 loops for Debate Transcript Translations took  12.46 seconds.\n",
      "94 loops for October 6, 1976 Debate Transcript took  6.48 seconds.\n",
      "686 loops for October 8, 2004 Debate Transcript took  8.73 seconds.\n",
      "479 loops for October 19, 1992 Debate Transcript took  6.51 seconds.\n",
      "119 loops for October 9, 1996 Debate Transcript took  8.52 seconds.\n",
      "131 loops for October 28, 1980 Debate Transcript took  6.46 seconds.\n",
      "75 loops for September 26, 1960 Debate Transcript took  6.71 seconds.\n",
      "60 loops for Debate Transcripts took  6.42 seconds.\n",
      "178 loops for October 17, 2000 Debate Transcript took  13.61 seconds.\n",
      "547 loops for October 16, 2012 Debate Transcript took  24.81 seconds.\n",
      "156 loops for October 5, 1988 Debate Transcripts took  6.55 seconds.\n",
      "124 loops for October 11, 1984 Debate Transcript took  9.00 seconds.\n",
      "676 loops for October 11, 2012 Debate Transcript took  6.58 seconds.\n",
      "203 loops for October 15, 1992 First Half Debate Transcript took  6.78 seconds.\n",
      "255 loops for October 21, 1984 Debate Transcript took  6.58 seconds.\n",
      "96 loops for October 22, 1976 Debate Transcript took  10.57 seconds.\n",
      "178 loops for October 13, 1988 Debate Transcript took  6.46 seconds.\n",
      "638 loops for October 5, 2004 Transcript took  8.80 seconds.\n",
      "543 loops for October 13, 2004 Debate Transcript took  6.55 seconds.\n",
      "560 loops for October 13, 1992 Debate Transcript took  8.54 seconds.\n",
      "238 loops for October 11, 2000 Debate Transcript took  6.77 seconds.\n",
      "312 loops for October 7, 1984 Debate Transcript took  8.54 seconds.\n",
      "1017 loops for September 26, 2008 Debate Transcript took  6.69 seconds.\n",
      "99 loops for September 23, 1976 Debate Transcript took  6.52 seconds.\n",
      "72 loops for October 7, 1960 Debate Transcript took  8.75 seconds.\n",
      "464 loops for October 9, 2016 Debate Transcript took  7.17 seconds.\n",
      "668 loops for October 4, 2016 Debate Transcript took  8.85 seconds.\n",
      "420 loops for October 2, 2008 Debate Transcript took  6.75 seconds.\n",
      "481 loops for October 3, 2012 Debate Transcript took  6.87 seconds.\n",
      "75 loops for October 13, 1960 Debate Transcript took  8.51 seconds.\n",
      "108 loops for October 11, 1992 First Half Debate Transcript took  30.92 seconds.\n",
      "88 loops for September 21, 1980 Debate Transcript took  6.44 seconds.\n",
      "495 loops for October 7, 2008 Debate Transcript took  8.53 seconds.\n",
      "238 loops for October 6, 1996 Debate Transcript took  6.51 seconds.\n",
      "241 loops for September 25, 1988 Debate Transcript took  6.49 seconds.\n",
      "172 loops for October 11, 1992 Second Half Debate Transcript took  10.54 seconds.\n",
      "243 loops for October 15, 1992 Second Half Debate Transcript took  6.68 seconds.\n",
      "525 loops for October 19, 2016 Debate Transcript took  8.51 seconds.\n",
      "146 loops for October 16, 1996 Debate Transcript took  6.52 seconds.\n",
      "495 loops for October 22, 2012 Debate Transcript took  8.63 seconds.\n",
      "534 loops for September 26, 2016 Debate Transcript took  6.75 seconds.\n",
      "54 loops for October 21, 1960 Debate Transcript took  8.51 seconds.\n",
      "532 loops for September 30. 2004 Debate Transcript took  6.57 seconds.\n",
      "492 loops for October 15, 2008 Debate Transcript took  8.83 seconds.\n",
      "Finished in  399.95 seconds\n"
     ]
    }
   ],
   "source": [
    "# run the function to pull the transcripts\n",
    "transcript_scraper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script typically takes approx. 6.5 minutes to extract all of the transcripts\n",
    "### Output is the transcripts_df.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
